{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import timedelta\n",
    "import time\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "#from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from functools import partial\n",
    "import itertools\n",
    "\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCol2Count(df,col):\n",
    "    return dict(df[col].value_counts())\n",
    "    \n",
    "def __removeChatteringAlarmsHelper(alarms,chattering_timedelta_threshold, chattering_count_threshold):\n",
    "        \"\"\"Find the chatterings in an alarms list from the same source.  \n",
    "        \"\"\"\n",
    "\n",
    "        alarms_without_chattering = []\n",
    "        alarms = [alarm for alarm in sorted(alarms, key=lambda arg: arg[\"StartTime\"], reverse=False)]\n",
    "        i = 0\n",
    "        j = 0\n",
    "\n",
    "        while i < (len(alarms)):\n",
    "            alarms_without_chattering.append(alarms[i])\n",
    "            prev_start = alarms[i][\"StartTime\"]\n",
    "            prev_end = alarms[i][\"EndTime\"]\n",
    "            count_alarms = 0\n",
    "            j = i + 1\n",
    "            while j < len(alarms):\n",
    "                next_start = alarms[j][\"StartTime\"]\n",
    "                next_end = alarms[j][\"EndTime\"]\n",
    "\n",
    "                # this assert is very important: the prev alarm has to turn off before the start of\n",
    "                # the next one\n",
    "                assert(prev_start <= next_start)\n",
    "                assert(prev_end <= next_start)\n",
    "                assert(prev_end <= next_end)\n",
    "\n",
    "                delta = timedelta.total_seconds(next_start - prev_start)\n",
    "                assert (delta >= 0)\n",
    "                \n",
    "                if delta > chattering_timedelta_threshold:\n",
    "                    break\n",
    "                count_alarms += 1\n",
    "                \n",
    "                j += 1\n",
    "            \n",
    "            if count_alarms >= chattering_count_threshold:\n",
    "                i = j\n",
    "            else:\n",
    "                i += 1\n",
    "\n",
    "        return alarms_without_chattering\n",
    "    \n",
    "def tempFun(df,chat_delta,chat_count,sname):\n",
    "\n",
    "    alarms_without_chatterings = []\n",
    "    df_source = df.loc[df['SourceName'].isin([sname])]\n",
    "\n",
    "    for condition in df_source[\"Condition\"].unique():\n",
    "        df_condition = df_source.loc[df_source['Condition'].isin([condition])]\n",
    "        alarms = __removeChatteringAlarmsHelper(df_condition.to_dict(orient=\"records\"),chattering_timedelta_threshold=chat_delta,chattering_count_threshold=chat_count)\n",
    "        alarms_without_chatterings = alarms_without_chatterings + alarms\n",
    "    \n",
    "    return alarms_without_chatterings\n",
    "\n",
    "def removeChatteringAlarms(df,chattering_timedelta_threshold=None,chat_count=None):\n",
    "\n",
    "    # for sname in df[\"SourceName\"].unique():\n",
    "\n",
    "    alarms_without_chatterings = [] \n",
    "    sources=[sname for sname in df[\"SourceName\"].unique()] \n",
    "\n",
    "    myFun =  partial(tempFun,df,chattering_timedelta_threshold,chat_count)\n",
    "    \n",
    "\n",
    "    with Pool(3) as p:\n",
    "        alarms_without_chatterings = p.map(myFun, sources)\n",
    "\n",
    "    alarms_without_chatterings = list(itertools.chain.from_iterable(alarms_without_chatterings))\n",
    "    return pd.DataFrame(alarms_without_chatterings)\n",
    "\n",
    "\n",
    "\n",
    "class AlarmsProcessing:\n",
    "    def __init__(self,config) -> None:\n",
    "        self.config = config\n",
    "        self.alias2name = None\n",
    "        self.name2alias = None\n",
    "        self.df = pd.read_csv(self.config['file-path'], low_memory=False, usecols=self.config['usecols'],parse_dates=self.config['date-cols'])\n",
    "        if self.config['alias']:\n",
    "            self.convertSourceNamesToAlias()\n",
    "        \n",
    "        for m in self.df[\"Year-Month\"].unique():\n",
    "            \n",
    "            month_df = self.df[self.df[\"Year-Month\"].isin([m])].sort_values(by='StartTime', ascending=True).reset_index(drop=True)\n",
    "\n",
    "            days = sorted(list(month_df['Day'].unique()))\n",
    "            print(f\"[{m}],Days:{days}\")\n",
    "    \n",
    "    def convertSourceNamesToAlias(self):\n",
    "        alias2name = {f\"A{k}\": v for k, v in enumerate(self.df[\"SourceName\"].unique())}\n",
    "        name2alias = {v: k for k, v in alias2name.items()}\n",
    "        self.df[\"SourceName\"] = self.df[\"SourceName\"].apply(lambda sname: name2alias[sname])\n",
    "        self.alias2name = alias2name\n",
    "        self.name2alias = name2alias\n",
    "        # return name2alias, alias2name\n",
    "\n",
    "    def removeChatteringAlarms(self,df,chattering_timedelta_threshold=60,chattering_count_threshold=2):\n",
    "        return removeChatteringAlarms(df=df,chattering_timedelta_threshold=chattering_timedelta_threshold,chat_count=chattering_count_threshold)\n",
    "\n",
    "    def removeMomentaryAlarms(self,df,monmentarly_filter=None):\n",
    "        df = df[(df[\"TimeDelta\"] > monmentarly_filter)].reset_index(drop=True)\n",
    "        return df\n",
    "\n",
    "    def removeStalingAlarms(self,df,staling_filter=None):\n",
    "        df =  df[(df[\"TimeDelta\"] < staling_filter)].reset_index(drop=True)\n",
    "        return df\n",
    "\n",
    "    def removeConditionsAlarms(self,df,conditions_filter):\n",
    "        df = df[~df[\"Condition\"].isin(conditions_filter)].reset_index(drop=True)\n",
    "        return df\n",
    "\n",
    "    def removeSources(self,df, sources_filter):\n",
    "        df = df[(~df[\"SourceName\"].isin(sources_filter))].reset_index(drop=True)\n",
    "        return df\n",
    "    \n",
    "    def removeSourcesBasedOnMinCount(self,df,min_alarms_per_source_filter):\n",
    "        source2count = dict(df[\"SourceName\"].value_counts())\n",
    "        select_sources = [k for k, v in source2count.items() if v >= min_alarms_per_source_filter]\n",
    "        df = df[df[\"SourceName\"].isin(select_sources)]\n",
    "        return df\n",
    "\n",
    "    def getDFWithCommonSourcesInAllMonths(self,df):\n",
    "        each_month_source_names = [[sname for sname in df[df[\"Year-Month\"]==month][\"SourceName\"].unique()] for month in df[\"Year-Month\"].unique()]\n",
    "        common_sourcenames_in_all_months = set.intersection(*[set(l) for l in each_month_source_names])\n",
    "        df = df[df[\"SourceName\"].isin(common_sourcenames_in_all_months)]\n",
    "        return df\n",
    "      \n",
    "    def updatSourceNamewithCondition(self,df):\n",
    "        def _concatenateSourceNameAndCondition(sname, condition):\n",
    "            return sname+\"-\"+condition\n",
    "        df[\"SourceName\"] = df[[\"SourceName\", \"Condition\"]].apply(\n",
    "            lambda arg: _concatenateSourceNameAndCondition(*arg), axis=1)\n",
    "        return df\n",
    "    \n",
    "    def getCondition2Sources(self,df,condition):\n",
    "        return df[df[\"Condition\"]==condition][\"SourceName\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrepareDataset:\n",
    "    def __init__(self,config) -> None:\n",
    "        self.config = config\n",
    "\n",
    "    def getSeqsFromAlarmsDF(self,df,seq_duration_gap,filter_short_seq):\n",
    "        \"\"\"This function converts alarm dataframe into sequences of alarms.\n",
    "\n",
    "        Args:\n",
    "            df (_type_): Alarm dataset\n",
    "            seq_duration_gap (_type_): The duration gap that will define the sequences. If it excesses this limit, upcoming alarms will be added in another sequence\n",
    "            filter_short_seq (_type_): The minimum length of sequences. \n",
    "\n",
    "        Returns:\n",
    "            _type_: list of sequences of alarms.\n",
    "        \"\"\"\n",
    "        print(f\">> Duration to next seq: {seq_duration_gap}, ignore seq len: {filter_short_seq}\")\n",
    "\n",
    "        list_of_sequences = []    \n",
    "        alarms= df.sort_values(by='StartTime', ascending=True).reset_index(drop=True).to_dict(orient=\"records\")  # records’ : list like [{column -> value}, … , {column -> value}]\n",
    "        \n",
    "        alarms = [alarm for alarm in sorted(alarms, key=lambda arg: arg[\"StartTime\"], reverse=False)] # sorting\n",
    "\n",
    "        # print('check',len(alarms))\n",
    "        assert alarms[0]['StartTime'] < alarms[-1]['StartTime']\n",
    "        i =0\n",
    "        j= 0\n",
    "\n",
    "        max_seq_len = -1\n",
    "        while i <len(alarms):\n",
    "            prev_start = alarms[i][\"StartTime\"]\n",
    "            seq = []\n",
    "            seq.append(alarms[i])\n",
    "            j = i+1\n",
    "            while j < len(alarms):    \n",
    "                next_start = alarms[j][\"StartTime\"]\n",
    "                delta = timedelta.total_seconds(next_start - prev_start)\n",
    "                # print(delta)\n",
    "                assert delta >= 0\n",
    "                if delta >= seq_duration_gap:\n",
    "                    break\n",
    "\n",
    "                seq.append(alarms[j])\n",
    "                j += 1\n",
    "            i = j\n",
    "\n",
    "            if len(seq) > max_seq_len:\n",
    "                max_seq_len = len(seq)\n",
    "            \n",
    "            if len(seq)>=filter_short_seq:\n",
    "                seq = [alarm for alarm in sorted(seq, key=lambda arg: arg[\"StartTime\"], reverse=False)]\n",
    "                seq = [alarm[\"SourceName\"] for alarm in seq]\n",
    "                list_of_sequences.append(seq)\n",
    "        \n",
    "        \n",
    "        return list_of_sequences, max_seq_len\n",
    "\n",
    "\n",
    "    def splitDFtoTrainValidDfsPerMonthByRows(self,df,p=0.2):    \n",
    "        tarain_dfs = []\n",
    "        valid_dfs = []\n",
    "        for m in df[\"Year-Month\"].unique():\n",
    "            \n",
    "            month_df = df[(df[\"Year-Month\"].isin([m]))].sort_values(by='StartTime', ascending=True).reset_index(drop=True)\n",
    "\n",
    "            train_df = month_df[0:int(len(month_df)*(1-p))]\n",
    "            train_df = train_df.reset_index(drop=True)\n",
    "            valid_df = month_df[int(len(month_df)*(1-p)):]\n",
    "            valid_df = valid_df.reset_index(drop=True)\n",
    "            assert len(train_df)+len(valid_df) == len(month_df)\n",
    "            tarain_dfs.append(train_df)\n",
    "            valid_dfs.append(valid_df)\n",
    "        \n",
    "        t_df = pd.concat(tarain_dfs, ignore_index=True).sort_values(by='StartTime', ascending=True).reset_index(drop=True)\n",
    "        v_df = pd.concat(valid_dfs, ignore_index=True).sort_values(by='StartTime', ascending=True).reset_index(drop=True)\n",
    "\n",
    "        assert len(t_df)+len(v_df) == len(df) \n",
    "\n",
    "        return t_df, v_df\n",
    "    \n",
    "    def splitDFtoTrainValidDfsPerMonthByDays(self,df,p=0.2):    \n",
    "        tarain_dfs = []\n",
    "        valid_dfs = []\n",
    "        for m in df[\"Year-Month\"].unique():\n",
    "            \n",
    "            month_df = df[(df[\"Year-Month\"].isin([m]))].sort_values(by='StartTime', ascending=True).reset_index(drop=True)\n",
    "\n",
    "            days = sorted(list(month_df['Day'].unique()))\n",
    "            # if len(days)<5:\n",
    "            #     print(f\"Skipping : [{m}],Days:{days}\")\n",
    "            #     continue\n",
    "            \n",
    "            print(f\"[{m}]: Days: {days}\")\n",
    "\n",
    "            train_days = days[0:len(days)-int(len(days)*p)]\n",
    "            valid_days = days[len(days)-int(len(days)*p):len(days)]\n",
    "            # print(f\"[{m}]Train Days: {train_days}, val days = {valid_days} \")\n",
    "\n",
    "            train_df = month_df[month_df['Day'].isin(train_days)].reset_index(drop=True)\n",
    "            valid_df = month_df[month_df['Day'].isin(valid_days)].reset_index(drop=True)\n",
    "\n",
    "            assert len(train_df)+len(valid_df) == len(month_df)\n",
    "            tarain_dfs.append(train_df)\n",
    "            valid_dfs.append(valid_df)\n",
    "        \n",
    "        t_df = pd.concat(tarain_dfs, ignore_index=True).sort_values(by='StartTime', ascending=True).reset_index(drop=True)\n",
    "        v_df = pd.concat(valid_dfs, ignore_index=True).sort_values(by='StartTime', ascending=True).reset_index(drop=True)\n",
    "\n",
    "        # assert len(t_df)+len(v_df) == len(df) \n",
    "\n",
    "        return t_df, v_df\n",
    "    \n",
    "    def writeSequeces2TokenFile(self,file_path,li_of_seqs):\n",
    "        with open(file_path,\"w\") as f:\n",
    "            for seq in li_of_seqs:\n",
    "                f.write(f\"{' '.join(seq)}\\n\")\n",
    "        \n",
    "        print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2020, 3)],Days:[1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 21, 22]\n",
      "[(2019, 7)],Days:[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
      "[(2019, 8)],Days:[1, 2, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31]\n",
      "[(2019, 3)],Days:[6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n",
      "[(2019, 10)],Days:[1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
      "[(2019, 11)],Days:[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 22, 24, 25, 26, 27, 28, 29, 30]\n",
      "[(2019, 9)],Days:[1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 22, 23, 24, 25, 26, 27, 28, 30]\n",
      "[(2020, 2)],Days:[1, 2, 4, 5, 6, 7, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29]\n",
      "[(2019, 5)],Days:[1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31]\n",
      "[(2019, 6)],Days:[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
      "[(2019, 12)],Days:[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31]\n",
      "[(2019, 4)],Days:[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
      "[(2020, 1)],Days:[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31]\n",
      "Total Time to load the data  3.0279159545898438e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SourceName</th>\n",
       "      <th>Condition</th>\n",
       "      <th>StartTime</th>\n",
       "      <th>EndTime</th>\n",
       "      <th>TimeDelta</th>\n",
       "      <th>Year-Month</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48TIC2026</td>\n",
       "      <td>VEL-</td>\n",
       "      <td>2020-03-01 00:00:03</td>\n",
       "      <td>2020-03-01 00:00:05</td>\n",
       "      <td>2.0</td>\n",
       "      <td>(2020, 3)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48TIC2026</td>\n",
       "      <td>VEL-</td>\n",
       "      <td>2020-03-01 00:00:07</td>\n",
       "      <td>2020-03-01 00:00:08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(2020, 3)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48TIC2026</td>\n",
       "      <td>VEL-</td>\n",
       "      <td>2020-03-01 00:00:10</td>\n",
       "      <td>2020-03-01 00:00:11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(2020, 3)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48TIC2026</td>\n",
       "      <td>VEL-</td>\n",
       "      <td>2020-03-01 00:00:18</td>\n",
       "      <td>2020-03-01 00:00:20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>(2020, 3)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48TIC2026</td>\n",
       "      <td>VEL-</td>\n",
       "      <td>2020-03-01 00:00:22</td>\n",
       "      <td>2020-03-01 00:00:23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(2020, 3)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12222295</th>\n",
       "      <td>47TIC1514</td>\n",
       "      <td>LO</td>\n",
       "      <td>2020-01-09 02:54:38</td>\n",
       "      <td>2020-01-09 03:05:56</td>\n",
       "      <td>678.0</td>\n",
       "      <td>(2020, 1)</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12222296</th>\n",
       "      <td>47PI055</td>\n",
       "      <td>LL</td>\n",
       "      <td>2020-01-09 02:53:46</td>\n",
       "      <td>2020-01-09 03:23:32</td>\n",
       "      <td>1786.0</td>\n",
       "      <td>(2020, 1)</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12222297</th>\n",
       "      <td>47FI1503C</td>\n",
       "      <td>LLL</td>\n",
       "      <td>2020-01-23 14:02:23</td>\n",
       "      <td>2020-01-23 14:02:24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(2020, 1)</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12222298</th>\n",
       "      <td>47PI1517B</td>\n",
       "      <td>LLL</td>\n",
       "      <td>2020-01-09 02:54:19</td>\n",
       "      <td>2020-01-09 02:58:34</td>\n",
       "      <td>255.0</td>\n",
       "      <td>(2020, 1)</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12222299</th>\n",
       "      <td>47TI1538</td>\n",
       "      <td>LO</td>\n",
       "      <td>2020-01-09 03:03:37</td>\n",
       "      <td>2020-01-09 03:17:07</td>\n",
       "      <td>810.0</td>\n",
       "      <td>(2020, 1)</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12222300 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         SourceName Condition           StartTime             EndTime  \\\n",
       "0         48TIC2026      VEL- 2020-03-01 00:00:03 2020-03-01 00:00:05   \n",
       "1         48TIC2026      VEL- 2020-03-01 00:00:07 2020-03-01 00:00:08   \n",
       "2         48TIC2026      VEL- 2020-03-01 00:00:10 2020-03-01 00:00:11   \n",
       "3         48TIC2026      VEL- 2020-03-01 00:00:18 2020-03-01 00:00:20   \n",
       "4         48TIC2026      VEL- 2020-03-01 00:00:22 2020-03-01 00:00:23   \n",
       "...             ...       ...                 ...                 ...   \n",
       "12222295  47TIC1514        LO 2020-01-09 02:54:38 2020-01-09 03:05:56   \n",
       "12222296    47PI055        LL 2020-01-09 02:53:46 2020-01-09 03:23:32   \n",
       "12222297  47FI1503C       LLL 2020-01-23 14:02:23 2020-01-23 14:02:24   \n",
       "12222298  47PI1517B       LLL 2020-01-09 02:54:19 2020-01-09 02:58:34   \n",
       "12222299   47TI1538        LO 2020-01-09 03:03:37 2020-01-09 03:17:07   \n",
       "\n",
       "          TimeDelta Year-Month  Day  \n",
       "0               2.0  (2020, 3)    1  \n",
       "1               1.0  (2020, 3)    1  \n",
       "2               1.0  (2020, 3)    1  \n",
       "3               2.0  (2020, 3)    1  \n",
       "4               1.0  (2020, 3)    1  \n",
       "...             ...        ...  ...  \n",
       "12222295      678.0  (2020, 1)    9  \n",
       "12222296     1786.0  (2020, 1)    9  \n",
       "12222297        1.0  (2020, 1)   23  \n",
       "12222298      255.0  (2020, 1)    9  \n",
       "12222299      810.0  (2020, 1)    9  \n",
       "\n",
       "[12222300 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\n",
    "    'file-path': \"/Users/hamzagorgulu/Desktop/thesis/Waris Final/tupras/data/final-all-months-alarms-with-day-filtered.csv\",\n",
    "    'usecols':[\"SourceName\", \"Condition\", \"StartTime\",\"EndTime\",\"TimeDelta\",\"Year-Month\",'Day'],\n",
    "    'date-cols':   [\"StartTime\", \"EndTime\"],\n",
    "    'alias': False\n",
    "}\n",
    "\n",
    "alarm = AlarmsProcessing(config=config)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "print(\"Total Time to load the data \", time.time()-start)\n",
    "\n",
    "alarm.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'VEL+': 3784276,\n",
       " 'IOP': 3660184,\n",
       " 'VEL-': 3386264,\n",
       " 'ALM': 439927,\n",
       " 'IOP-': 236727,\n",
       " 'LLL': 177912,\n",
       " 'LTRP': 170050,\n",
       " 'CNF': 168540,\n",
       " 'LL': 59779,\n",
       " 'LO': 47511,\n",
       " 'HI': 30722,\n",
       " 'HHH': 24753,\n",
       " 'HTRP': 14119,\n",
       " 'ANS-': 12705,\n",
       " 'HH': 4559,\n",
       " 'DV-': 2424,\n",
       " 'DV+': 1066,\n",
       " 'MLO': 645,\n",
       " 'ANS+': 54,\n",
       " 'MHI': 53,\n",
       " 'OOP': 28,\n",
       " 'CERR': 1,\n",
       " 'TRIP': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con2count=getCol2Count(df=alarm.df,col='Condition')\n",
    "con2count\n",
    "\n",
    "#Important  Trip, HHH, HTRP, LTRP, LLL, -> most imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ALM': 439927,\n",
       " 'LLL': 177912,\n",
       " 'LTRP': 170050,\n",
       " 'CNF': 168540,\n",
       " 'LL': 59779,\n",
       " 'LO': 47511,\n",
       " 'HI': 30722,\n",
       " 'HHH': 24753,\n",
       " 'HTRP': 14119,\n",
       " 'ANS-': 12705,\n",
       " 'HH': 4559,\n",
       " 'DV-': 2424,\n",
       " 'DV+': 1066,\n",
       " 'MLO': 645,\n",
       " 'ANS+': 54,\n",
       " 'MHI': 53,\n",
       " 'OOP': 28,\n",
       " 'CERR': 1,\n",
       " 'TRIP': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove communication alarms\n",
    "df = alarm.removeConditionsAlarms(df=alarm.df,conditions_filter=[\"IOP\", \"IOP-\",'VEL-','VEL+'])\n",
    "con2count=getCol2Count(df=df,col='Condition')\n",
    "con2count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndf = alarm.removeChatteringAlarms(df=df,chattering_timedelta_threshold=60,chattering_count_threshold=3)\\ncon2count=getCol2Count(df=df,col='Condition')\\ncon2count\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "df = alarm.removeChatteringAlarms(df=df,chattering_timedelta_threshold=60,chattering_count_threshold=3)\n",
    "con2count=getCol2Count(df=df,col='Condition')\n",
    "con2count\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3 = alarm.removeConditionsAlarms(df=alarm.df,conditions_filter=[\"IOP\", \"IOP-\",'VEL+','VEL-'])\n",
    "# con2count=getCol2Count(df=df3,col='Condition')\n",
    "# print(con2count)\n",
    "# df4 = removeChatteringAlarms(df=df3,chattering_timedelta_threshold=60, chat_count =2)\n",
    "# con2count=getCol2Count(df=df4,col='Condition')\n",
    "# con2count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total = 0\n",
    "# for cond,count in getCol2Count(df=df,col='Condition').items(): \n",
    "#     l = df[df['Condition']==cond][\"SourceName\"].unique()\n",
    "#     total += len(l)\n",
    "\n",
    "#     print(f\">>{cond},{count},{len(l)}\")\n",
    "\n",
    "\n",
    "# print(len(getCol2Count(df,col='SourceName')),total)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>ALM,437466,45\n",
      ">>LLL,177271,31\n",
      ">>LTRP,169602,27\n",
      ">>CNF,168375,9\n",
      ">>LL,59263,78\n",
      ">>LO,46023,100\n",
      ">>HI,29502,106\n",
      ">>HHH,24448,11\n",
      ">>HTRP,14021,10\n",
      ">>ANS-,12700,2\n",
      ">>HH,4256,69\n",
      ">>DV-,2336,26\n",
      ">>DV+,988,23\n",
      ">>MLO,632,1\n",
      ">>ANS+,54,1\n",
      ">>MHI,51,2\n",
      ">>OOP,6,1\n",
      "218 542\n"
     ]
    }
   ],
   "source": [
    "df2 = alarm.removeSourcesBasedOnMinCount(df,min_alarms_per_source_filter=70)\n",
    "total = 0\n",
    "for cond,count in getCol2Count(df=df2,col='Condition').items(): \n",
    "    l = df2[df2['Condition']==cond][\"SourceName\"].unique()\n",
    "    total += len(l)\n",
    "\n",
    "    print(f\">>{cond},{count},{len(l)}\")\n",
    "\n",
    "\n",
    "print(len(getCol2Count(df2,col='SourceName')),total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_sources = []\n",
    "\n",
    "# for s in df[\"SourceName\"].unique():\n",
    "#     # print(len(df2[df2['SourceName']==s]['Condition'].unique()))\n",
    "#     if len(df[df['SourceName']==s]['Condition'].unique())==1:\n",
    "#         temp_sources.append(s)\n",
    "\n",
    "\n",
    "# print(temp_sources)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2020, 3)]: Days: [1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 21, 22]\n",
      "[(2019, 7)]: Days: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
      "[(2019, 8)]: Days: [1, 2, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31]\n",
      "[(2019, 3)]: Days: [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n",
      "[(2019, 10)]: Days: [1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
      "[(2019, 11)]: Days: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 22, 24, 25, 26, 27, 28, 29, 30]\n",
      "[(2019, 9)]: Days: [1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 22, 23, 24, 25, 26, 27, 28, 30]\n",
      "[(2020, 2)]: Days: [1, 2, 4, 5, 6, 7, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29]\n",
      "[(2019, 6)]: Days: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
      "[(2019, 5)]: Days: [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31]\n",
      "[(2019, 12)]: Days: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31]\n",
      "[(2019, 4)]: Days: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
      "[(2020, 1)]: Days: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31]\n",
      "[(2019, 3)]: Days: [19, 20, 21, 22, 23]\n",
      "[(2019, 4)]: Days: [23, 24, 25, 26, 27, 28, 29, 30]\n",
      "[(2019, 5)]: Days: [23, 24, 25, 27, 28, 29, 30, 31]\n",
      "[(2019, 6)]: Days: [23, 24, 25, 26, 27, 28, 29, 30]\n",
      "[(2019, 7)]: Days: [23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
      "[(2019, 8)]: Days: [25, 26, 27, 28, 29, 30, 31]\n",
      "[(2019, 9)]: Days: [23, 24, 25, 26, 27, 28, 30]\n",
      "[(2019, 10)]: Days: [23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
      "[(2019, 11)]: Days: [22, 24, 25, 26, 27, 28, 29, 30]\n",
      "[(2019, 12)]: Days: [23, 24, 25, 26, 27, 28, 29, 31]\n",
      "[(2020, 1)]: Days: [23, 24, 25, 27, 28, 29, 30, 31]\n",
      "[(2020, 2)]: Days: [22, 23, 24, 25, 26, 28, 29]\n",
      "[(2020, 3)]: Days: [17, 18, 19, 21, 22]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "FINAL_DF = df2\n",
    "\n",
    "alarm_dataset = PrepareDataset({})\n",
    "train_df, valid_df = alarm_dataset.splitDFtoTrainValidDfsPerMonthByDays(FINAL_DF,p=0.3)\n",
    "valid_df, test_df = alarm_dataset.splitDFtoTrainValidDfsPerMonthByDays(valid_df,p=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Duration to next seq: 900, ignore seq len: 0\n",
      ">> Duration to next seq: 900, ignore seq len: 0\n",
      ">> Duration to next seq: 900, ignore seq len: 0\n"
     ]
    }
   ],
   "source": [
    "seqs_train, _  = alarm_dataset.getSeqsFromAlarmsDF(train_df,seq_duration_gap=60*15,filter_short_seq=0)\n",
    "seqs_valid, _  = alarm_dataset.getSeqsFromAlarmsDF(valid_df,seq_duration_gap=60*15,filter_short_seq=0)\n",
    "seqs_test, _  = alarm_dataset.getSeqsFromAlarmsDF(test_df,seq_duration_gap=60*15,filter_short_seq=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19919 6581 1029\n"
     ]
    }
   ],
   "source": [
    "print(len(seqs_train), len(seqs_valid), len(seqs_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from gloVe_helpers.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     /Users/hamzagorgulu/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# now lets implement the gloVe word embedding.\n",
    "import import_ipynb\n",
    "from gloVe_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "distint_train_alarms, num_train_alarm_sources = distinct_words(seqs_train)\n",
    "alarms = distint_train_alarms[40:45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Truncated SVD over 218 words...\n",
      "Done.\n",
      "[5285.66182423 3973.03485826]\n"
     ]
    }
   ],
   "source": [
    "M, word2ind = compute_co_occurrence_matrix(seqs_train, window_size=4)\n",
    "M_reduced = reduce_to_k_dim(M)\n",
    "print(M_reduced[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Rescale (normalize) the rows to make them each of unit-length\n",
    "M_lengths = np.linalg.norm(M_reduced, axis=1)\n",
    "M_normalized = M_reduced / M_lengths[:, np.newaxis] # broadcasting\n",
    "\n",
    "\n",
    "alarms = alarms\n",
    "plot_embeddings(M_normalized, word2ind, alarms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alarm_dataset.writeSequeces2TokenFile(file_path=\"../.data/train.tokens\",li_of_seqs=seqs_train)\n",
    "alarm_dataset.writeSequeces2TokenFile(file_path=\"../.data/val.tokens\",li_of_seqs=seqs_valid)\n",
    "alarm_dataset.writeSequeces2TokenFile(file_path=\"../.data/test.tokens\",li_of_seqs=seqs_test)\n",
    "\n",
    "print(\"DataSet is complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duration_from_1_seq_to_next = 60*15 # duration in seconds\n",
    "# filter_short_seq = 3 # remove the sequence whose size is less than 4\n",
    "# li_of_seqs,max_seq_len = getSequenceOfWholeData(df_rnn,duration_from_1_seq_to_next,filter_short_seq)\n",
    "# print(len(li_of_seqs))\n",
    "# print(li_of_seqs[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq_len_2_count ={}\n",
    "# for seq in li_of_seqs:\n",
    "#     # seq = removeSameAlarms(seq)\n",
    "#     l = len(seq)\n",
    "#     seq_len_2_count[l] = 1+seq_len_2_count.get(l,0)\n",
    "\n",
    "# seq_len_2_count = {k:v for k,v in sorted(seq_len_2_count.items(), key=lambda t: t[1] )}\n",
    "# seq_len_2_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def removeSameAlarms(seq):\n",
    "#     new_seq = []\n",
    "\n",
    "#     new_seq.append(seq[0])\n",
    "\n",
    "#     for a in seq:\n",
    "\n",
    "#         if a == new_seq[-1]:\n",
    "#             continue\n",
    "#         new_seq.append(a)\n",
    "    \n",
    "#     return new_seq\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum(seq_len_2_count.keys())/len(seq_len_2_count.keys())\n",
    "# l = 5*['5']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9 (default, Apr 13 2022, 08:48:06) \n[Clang 13.1.6 (clang-1316.0.21.2.5)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
